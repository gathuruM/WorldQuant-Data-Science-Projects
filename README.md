<img align="right" src="https://upload.wikimedia.org/wikipedia/commons/7/72/WQU_logo_color.png" width="250">


# ⭐Applied Data Science Lab [2023]
<br>

The [Applied Data Science Lab](https://www.wqu.edu/programs/applied-ds-lab/), offered by *WorldQuant University*, is an immersive online program that equipped me with practical skills in addressing real-world, intricate challenges. <br> Throughout the program, I engaged in a series of comprehensive data science projects that helped me develop proficiency in data wrangling, analysis, model-building and effective communication through hands-on experience.

<br>

![](https://img.shields.io/badge/Project%201-Housing%20in%20Mexico-blue?style=for-the-badge)

   + Imported multiple CSV files from a private repository into a pandas DataFrame using for loops
   + Created preliminary and exploratory histograms, scatter plots, whisker plots and bar charts
   + Examined the relationship between variables by assessing **Pearson correlation** coefficients  
   + **Cleaned** and **wrangled raw data** by creating a **custom *wrangle* function**
<br> 

![](https://img.shields.io/badge/Project%202-Apartment%20Sales%20in%20Buenos%20Aires-orange?style=for-the-badge)

   + Built **ML pipelines** by means of *Ridge, OneHotEncoder, SimpleImputer, LinearRegression* and *make_pipeline* built-in *sklearn* functions
   + Applied **L2 Regularization** in order to prevent **overfitting or underfitting** in **Linear Regression** models
   + Created an **interactive dashboard** utilizing *ipywidgets* library to **module predictions** based on different input features
<br> 

![](https://img.shields.io/badge/Project%203-Air%20Quality%20in%20Nairobi-black?style=for-the-badge)

   + Connected to a **MongoDB server** using *pymongo* library to localize and extract the required data, **ETL**.
   + Applied rolling average, autocorrelation and lag operations to Times Series data variables.
   + Utilized **Train Test Split** procedures to create proper train and test datasets for a **Linear Regression** model.
   + Built, explored and interpreted **Partial/Auto Correlation Functions** plots.
   + Using statsmodels modules, constructed **Auto Regressive** and **ARMA** models and validated them via **Walk Forward** optimization.
   + Tuned the number of **lagged observations** and **moving avg. window size** via *GridSearchCV*.
   + Detected an **optimal balance** between **Model Performance** and **Computational Costs**
<br>

![](https://img.shields.io/badge/Project%204-Earthquake%20Damage%20in%20Nepal-red?style=for-the-badge)

   + Connected to a **SQL database** and wrangled data using *magic commands* and *sqlite3* library
   + Executed randomized **Train Test Split** to create proper **training, testing** and **validation datasets**
   + Elaborated **ML pipelines** utilizing *OrdinalEncoder, DecisionTreeClassifier, LogisticRegression* and *make_pipeline* built-in *sklearn* functions
   + Besides **computing** and **evaluating training** and **validation accuracy scores**:
       + For **Decission Tree algorithms**, tuned the **Tree’s depth** and assessed its predictions by assessing the **Gini importance** of its features
	   + For **Logistic Regression algorithms**, evaluated **Odds ratios** to explain its predictions
   + Reviewed the **Ethics of Environmental and Social impact** that Machine Learning models may lead to because of **data biases**
<br>


